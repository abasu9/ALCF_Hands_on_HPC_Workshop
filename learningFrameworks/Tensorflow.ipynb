{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c783791",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Tensorflow is an open source machine learning framework developed primarily by Google and released for a variety of languages.  We only focus on Python here, since that is the primary use of Tensorflow on ALCF systems.  For support for other modes, please contact support@alcf.anl.gov.\n",
    "\n",
    "The tensorflow documentation is here:\n",
    "https://www.tensorflow.org/\n",
    "\n",
    "To get started with Tensorflow, import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e194c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 15:14:42.460282: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 15:14:44.450891: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb4b54",
   "metadata": {},
   "source": [
    "## Tensorflow basics\n",
    "\n",
    "### `Tensor`\n",
    "Tensorflow uses the concept of `Tensors` as data types, and supports a variety of operations on them.  This document is not meant to be a tensorflow tutorial - instead, this is meant to inform you of the core concepts of using Tensorflow on Polaris, assuming you have some familiarity with Tensorflow already.\n",
    "\n",
    "You can learn more about tensors in detail here:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "### GPU Computing\n",
    "\n",
    "Tensorflow supports GPU operations for a large set of mathematical operations on Tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1d3c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "8.57 ms ± 58.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "(2, 500, 500)\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# CPU Computing:\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    cpu_input_data = tf.random.uniform(shape=(2,5000,500))\n",
    "\n",
    "    print(cpu_input_data.device)\n",
    "    # This runs on the CPU:\n",
    "\n",
    "    %timeit product = tf.linalg.matmul(cpu_input_data, cpu_input_data, transpose_a=True)\n",
    "\n",
    "    print(product.shape)\n",
    "    print(product.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6755d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "139 µs ± 5.33 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "(2, 500, 500)\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPU Computing:\n",
    "\n",
    "with tf.device(\"GPU\"):\n",
    "\n",
    "    gpu_input_data = tf.random.uniform(shape=(2,5000,500))\n",
    "\n",
    "\n",
    "    print(gpu_input_data.device)\n",
    "\n",
    "    # This runs on the GPU:\n",
    "\n",
    "    %timeit product = tf.linalg.matmul(gpu_input_data, gpu_input_data, transpose_a=True)\n",
    "\n",
    "    print(product.shape)\n",
    "    print(product.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10192cc3",
   "metadata": {},
   "source": [
    "### Getting access to Data\n",
    "\n",
    "We'll cover the Data Pipelines more completely in a later presentation.  For now, we'll use the cifar10 dataset, available from tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcebf1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# # Trying to run this on a mac?  Try these lines if you get an SSL error\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3702515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "# This data has 50000 images, of size 32x32 pixels and 3 RGB colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "328babfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "batch_data   = tf.convert_to_tensor(x_train[0:batch_size], dtype=tf.float32) # Take the first 10 images\n",
    "batch_labels = tf.convert_to_tensor(y_train[0:batch_size], dtype=tf.float32) # first 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee57cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5000, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cd6f1",
   "metadata": {},
   "source": [
    "### Machine Learning Models\n",
    "\n",
    "Tensorflow is primarily developed as a machine learning framework, so may operations like convolution, dense layers, etc. are all well supported.\n",
    "\n",
    "The easiest way to build a model is to use the Keras API for object-oriented model construction.  For example, building a few layers of a ResNet-likemodel can be done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "159655f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Call the parent class's __init__ to make this class functional with training loops:\n",
    "        super().__init__()\n",
    "        self.conv1  = tf.keras.layers.Conv2D(filters=16, kernel_size=[3,3], padding=\"same\")\n",
    "        self.conv2  = tf.keras.layers.Conv2D(filters=16, kernel_size=[3,3], padding=\"same\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "    \n",
    "        # Apply the first weights + activation:\n",
    "        outputs = tf.keras.activations.relu(self.conv1(inputs))\n",
    "        # Apply the second weights:\n",
    "\n",
    "        outputs = self.conv2(outputs)\n",
    "\n",
    "        # Perform the residual step:\n",
    "\n",
    "        outputs = outputs + inputs\n",
    "\n",
    "        # Second activation layer:\n",
    "        return tf.keras.activations.relu(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7db13d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Call the parent class's __init__ to make this class functional with training loops:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_init = tf.keras.layers.Conv2D(filters=16, kernel_size=1)\n",
    "        \n",
    "        self.res1 = ResidualBlock()\n",
    "        \n",
    "        self.res2 = ResidualBlock()\n",
    "        \n",
    "        # 10 filters for each class:\n",
    "        self.conv_final = tf.keras.layers.Conv2D(filters=10, kernel_size=1)\n",
    "        \n",
    "        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.conv_init(inputs)\n",
    "        \n",
    "        x = self.res1(x)\n",
    "        \n",
    "        x = self.res2(x)\n",
    "        \n",
    "        x = self.conv_final(x)\n",
    "        \n",
    "        return self.pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "564f4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model:\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dc501bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_data = model(batch_data)\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23892a77",
   "metadata": {},
   "source": [
    "You can visualize your networks easily with Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f3f0d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           multiple                  64        \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 4640      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 4640      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  170       \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,514\n",
      "Trainable params: 9,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b8be7",
   "metadata": {},
   "source": [
    "## Using Tensorflow on Polaris\n",
    "\n",
    "Tensorflow supports both GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36f9e3",
   "metadata": {},
   "source": [
    "# Automatic Differentiation\n",
    "\n",
    "The big advantage of the Machine Learning Frameworks is automatic differentiation.  Tensorflow supports automatic differentiation with the `GradientTape` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87c82e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa46b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    logits = model(batch_data)\n",
    "    loss = loss_function(batch_labels, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55226e3f",
   "metadata": {},
   "source": [
    "Get the \"normal\" derivatives (with respect to parameters) with the tape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ba08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308786e",
   "metadata": {},
   "source": [
    "You can also get gradients of other components, by asking the tape to `watch` tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec153a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(batch_data)\n",
    "    logits = model(batch_data)\n",
    "    loss = loss_function(batch_labels, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2274a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grads = tape.gradient(loss, batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a959062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5000, 32, 32, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_grads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59b857",
   "metadata": {},
   "source": [
    "## TF Functions\n",
    "\n",
    "Often, tensorflow code can run faster when you graph compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69432228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(batch_data)\n",
    "        loss = loss_function(batch_labels, logits)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95d1ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.7 ms ± 37.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gradient_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9053194",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step_traced = tf.function(gradient_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41e000d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.5 ms ± 28.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gradient_step_traced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec5262af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.5 ms ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gradient_step_traced()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d50b0c",
   "metadata": {},
   "source": [
    "Often, you can get further improvements with XLA:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f75d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step_XLA = tf.function(gradient_step, jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ad381c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 µs ± 80.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gradient_step_XLA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35e91c",
   "metadata": {},
   "source": [
    "### Reduced Precision\n",
    "\n",
    "A100 GPUs have support for faster matrix operations with mixed precision, which you can enable in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc065d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c86737b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step_XLA = tf.function(gradient_step, jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f29dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.3 ms ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gradient_step_XLA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466490f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
